---
title: "How does public behavior affect the spread of COVID-19?"
author: "Quang Vuong"
output:
  bookdown::pdf_document2
bibliography: bibliography.bib
csl: ieee.csl
---

```{r setup, include=FALSE, message = F}
knitr::opts_chunk$set(echo = F)
library(glmnet)
library(tidyverse)
library(MASS)
set.seed(20211127)
covid <- read.table("pblc_bhv_covid.csv",sep = ',', header=TRUE)
```

# Introduction

We wish to investigate how public behavior affects the spread of COVID-19 within a community. In particular, our goal is to identify which aspects of public behavior, such as visiting restaurants, visiting bars and using public transit, predict case counts. Since many other factors including population demographics, population density and policy decisions also affect the spread of COVID-19, it is best to focus on datasets for a sufficiently small geographical area (like a city or a county) so that the confounding factors unrelated to the study are controlled.

The present dataset, collected from the `{covidcast}` API, contains daily COVID-19 case counts for 88 days from June 5th, 2021 to September 5th, 2021, along with several indicators of public behavior, in Manhanttan, New York. The indicators of public behavior are:

- `distancing` = Percentage of survey respondents reporting that people maintained a distance of at least 6ft (%)
- `public_transit` = Percentage of survey respondents reporting that they used public transit in the last day (%)
- `worked_outside` = Percentage of survey respondents who was indoors (excluding home) in the last day (%)
- `large_events` = Percentage of survey respondents who attended a crowded event in the last day (%)
- `mask_prop` = Percentage of survey respondents who mostly wore a mask outside in the last week (%)
- `other_mask_prop` = Percentage of survey respondents saying that other people mostly wore a mask outside (%)
- `bar_visit` = Number of bar visits per 100000 people (visits per 100000 people)
- `resto_visit` = Number of restaurant visits per 100000 people (visits per 100000 people)

Most of these indicators are obtained from Facebook surveys. Taking into account the issues of survey data such as response bias and subjectivity of answers, it is extremely unlikely that the variables in the dataset track their true respective quantities. Instead, we opt to interpret these indicators as proxies of public behavior, which are potentially useful for prediction.

Now we will summarize our two objectives for this study:
\begin{enumerate}
\item Identify which of the above indicators are important in predicting COVID-19 case counts.
\item Identify a model which can be used to predict future COVID-19 case counts.
\end{enumerate}

Tupper et al. analyzed a model of COVID-19 transmission based on the specifics of social behavior such as reducing transmission rates through masks, social distancing and "bubbling", i.e. limiting social contact @tupper. They have concluded that distancing is the most powerful method to reduce transmission, while the effects of masking and bubbling are more situational but still significant. Therefore, based on this study, we would directly expect that `distancing`, `mask_prop` and `other_mask_prop` are important variables that predict lower COVID-19 case counts when at higher levels. It is feasible that the other predictors are important in predicting higher COVID-19 case counts when at higher levels as well, since an argument can be made that they do not pertain to bubbling. We then hypothesize that all predictors will appear in the final selected model.

# Exploratory data analysis

```{r desc-stat, eval = F}
means <- sapply(subset(covid,select=-date), mean)
sds <- sapply(subset(covid,select=-date), sd)
desc <- data.frame(Mean = means, Standard.deviation = sds)

knitr::kable(desc, digits = 2, caption = "Descriptive statistics of predictors and case counts.", format = "pipe")

```

```{r indiv-boxplots, echo=FALSE, fig.height=8, fig.cap = "Boxplots of individual predictors and case counts.", eval = F}
par(mfrow=c(3,3))
for (i in 2:10) {
  boxplot(covid[i], xlab=names(covid)[i], ylab="Values")
}
```
It is the most instructive to first look at how predictors are related to case counts and each other. We plot all predictors against the number of cases in Figure \@ref(fig:plots-against-cases). `distancing`, `bar_visit` and `large_events` appear to have two clusters with different mean case counts. On the other hand, `mask_prop`, `other_mask_prop`, `resto_visit` and `worked_outside` appear to have two trend lines. `public_transit` also looks like there are two trend lines, but both are quite flat. This strongly suggests that there are two clusters within the data that exhibit different relationships between case counts and public behavior.

```{r plots-against-cases, echo=FALSE, fig.height = 8, fig.cap = "Scatterplots of predictors against case counts."}

par(mfrow=c(3,3))

with(covid,plot(distancing,cases))
with(covid,plot(bar_visit,cases))
with(covid,plot(large_events,cases))
with(covid,plot(mask_prop,cases))
with(covid,plot(other_mask_prop,cases))
with(covid,plot(public_transit,cases))
with(covid,plot(resto_visit,cases))
with(covid,plot(worked_outside,cases))
```

To continue the examination of the dataset, we will now look at the covariance matrix of the predictors.

```{r correlations, fig.cap = "Entries of correlation matrix with high coefficients.", eval = T}
predictors <- subset(covid, select=-c(cases,date))

cor_pred <- cor(as.matrix(predictors))

for (i in 1:ncol(predictors)) {
  print(cor_pred[i, abs(cor_pred[i,]) > 0.6])
}
```

There is some substantial correlation between some predictors. In particular, `bar_visit`, `mask_prop`, `large_events` and `other_mask_prop` seem correlated with each other. Of these predictors, `large_events` appear to have two clusters with different mean case counts, while the remaining predictors seem to have two trend lines against case counts.

The most striking observation made so far is that there might be two clusters within the data that shows different relations between case counts and public behavior indicators, so we will now try to identify how the clusters are split. To do this, we attempt to fit a regression tree and look at the split at the root. Please note that we are only using this tree to expedite the exploration rather than seriously considering as a model. The fitted tree is plotted in Figure \@ref(fig:eda-tree). Initial inspection of this tree shows that there is clustering by date. After inspecting the plots of the predictors against `cases` within each cluster identified by the treem, it appears that splitting by date reduces the clustering behavior so that trends are now much clearer.

```{r eda-tree, echo = F, fig.height=3, fig.cap = "Regression tree to determine clusters in data.", eval = T}
library(rpart)

covid$time <- 1:nrow(covid)

eda_tree <- rpart(cases ~ .-date, data = covid, method = "anova")
plot(eda_tree, uniform = F, margin = 0.5)
text(eda_tree, pretty = T)
```



```{r plot-time-split, echo = F, fig.height=8, fig.cap = "Scatterplots of predictors against case counts on and before July 25th, 2021.", eval = F}
par(mfrow=c(3,3))

covid_ts1 <- covid[covid$time < 51.5, ]

with(covid_ts1,plot(distancing,cases))
with(covid_ts1,plot(bar_visit,cases))
with(covid_ts1,plot(large_events,cases))
with(covid_ts1,plot(mask_prop,cases))
with(covid_ts1,plot(other_mask_prop,cases))
with(covid_ts1,plot(public_transit,cases))
with(covid_ts1,plot(resto_visit,cases))
with(covid_ts1,plot(worked_outside,cases))

#Determines point in time where data is split.
#covid$date[covid$time == 51]
```

```{r plot-time-split2, echo = F, fig.height=8, fig.cap = "Scatterplots of predictors against case counts after July 25th, 2021.", eval = F}
par(mfrow=c(3,3))

covid_ts2 <- covid[covid$time >= 51.5, ]

with(covid_ts2,plot(distancing,cases))
with(covid_ts2,plot(bar_visit,cases))
with(covid_ts2,plot(large_events,cases))
with(covid_ts2,plot(mask_prop,cases))
with(covid_ts2,plot(other_mask_prop,cases))
with(covid_ts2,plot(public_transit,cases))
with(covid_ts2,plot(resto_visit,cases))
with(covid_ts2,plot(worked_outside,cases))
```

```{r corr_split, fig.cap = "Entries of correlation matrix with high coefficients for points on and before July 25th 2021.", eval = F}
predictors_ts <- subset(covid_ts1, select=-c(cases,date))

cor_pred_ts <- cor(as.matrix(predictors_ts))

for (i in 1:ncol(predictors_ts)) {
  print(cor_pred_ts[i, abs(cor_pred_ts[i,]) > 0.6])
}
```

```{r corr_whole_after_ts, fig.cap = "Entries of correlation matrix with high coefficients with `time` included.", eval = F}
predictors <- subset(covid, select=-c(cases,date))

cor_pred <- cor(as.matrix(predictors))

for (i in 1:ncol(predictors)) {
  print(cor_pred[i, abs(cor_pred[i,]) > 0.6])
}
```

Now, we will outline potential approaches to the analysis of this dataset. As mentioned above, we will analyze the both the original dataset and the dataset with time as an encoded categorical variable instead. Firstly, a full linear model will be fitted and interpreted from the inferential point of view to answer the first objective. Secondly, this model will be compared against ones obtained via a regularization approach and a variable selection approach. As interpretation is one of the goals of the analysis, we opt to avoid non-parametric approaches.

# Analysis and results

Let \(Y\) be a random variable that represents `cases` on a particular day, and let \(x_1,...,x_8\) denote the same for `distancing`, `bar_visit`,`large_events`,`mask_prop`,`other_mask_prop`,`public_transit`, `resto_visit`, and `worked_outside`. We posit the model
\[Y = \beta_0 + \sum_{i=1}^8 \beta_ix_i + \varepsilon\]
where \(\varepsilon\) is normally distributed with mean \(0\) and standard deviation \(\sigma^2\). We examine this model first because it is the simplest. The output of a least squares estimation procedure on the data with this model is as follows. The \(p\)-values are those calculated when testing the hypotheses \(H_0: \beta_i = 0\) versus \(H_a: \beta_i \neq 0\) for each \(\beta_i\) included the model, using the \(t\)-statistic as the test statistic.

```{r full, eval = T}
covid <- covid %>% mutate(ts = time >= 51.5)
full_mod <- lm(cases ~ .-date-time-ts, data = covid)
knitr::kable(data.frame(Coefficients = summary(full_mod)$coefficients[,1], p = summary(full_mod)$coefficients[,4]), format = "pipe", caption = "Summary of full model, no time split")
```
At the \(5\%\) significant level, only `distancing`, `bar_visit`, `mask_prop`, `other_mask_prop` and `public_transit` have an association with `cases`. Now, the existence of the time split identified in the Exploratory data analysis section informs us to posit the model, with the same notation,

\[Y = \beta_0 + \beta_1 t + \sum_{i=1}^8 \beta_{i+1}x_i + \sum_{i=1}^8 \beta_{i+9} tx_i + \varepsilon\]

where \(\varepsilon\) is as before and \(t = 0\) if the observation is on or before July 25th, 2021 and \(1\) otherwise. Hence, the time split is encoded as a categorical variable to identify observations as before or after the time split. The output of a least squares estimation procedure on the data for this model is shown below. The \(p\)-values are those calculated when testing the hypotheses \(H_0: \beta_i = 0\) versus \(H_a: \beta_i \neq 0\) for each \(\beta_i\) included in the model, using the \(t\)-statistic as the test statistic.

```{r full-by-time, eval = T}
full_mod1 <- lm(cases ~ ts*(.-date-time), data = covid)
knitr::kable(data.frame(Coefficients = summary(full_mod1)$coefficients[,1], p = summary(full_mod1)$coefficients[,4]), format = "pipe", caption = "Summary of full model with time split")
```

At the \(5\%\) significant level, only `large_events` and `other_mask_prop` have significant relationships with `cases` at all times, while `distancing`, `mask_prop` and `public_transit` are only significantly related to `cases` after the split point. Even though it appears that the main effect of the latter variables are insignificant, \(t\) is used to express the clusters in the data where there might be different relationships between `cases` and the predictors, so the conclusions made are sound.

Currently, for the first objective of the study, we have two competing models which provide different answers to the question of which predictors are significantly associated with `cases`. To decide which models to adopt conclusions from, we will check if the error assumptions hold for the two full models by looking at their residual and QQ plots.

```{r res-plots, fig.cap = "Diagnostic plots for full model without time split (top) and with time split (bottom)", fig.height = 4}
par(mfrow=c(2,2))
plot(full_mod, 1)
plot(full_mod, 2)
plot(full_mod1, 1)
plot(full_mod1, 2)
```

The full model that ignores the time split has a residual plot that has a very apparent line for observations with lower predicted cases, but it has a QQ plot which suggests only a small violation of the normal errors assumption. The full model that recognizes the time split has a more patternless residual plot, but there seems to be some heterocedasticity as well as a line on the left. The QQ plot for this model suggests a stronger violation of the normal errors assumption than the first model, but it is still minor. Therefore, we prefer the model that recognizes the time split for the first objective.

So far, we have pursued the first objective from an inferential standpoint, which slightly deviates from the objective as stated. We will now assume a predictive standpoint and compare models by their estimated mean squared prediction error. We will estimate this quantity with a leave-one-out cross-validation procedure that computes mean squared errors because it is flexible enough to adapt to the other model-fitting approaches that will be used in this study. The CV scores of the previous two full models are as follows. It is clear that the model that recognizes the time split performs much better.

```{r cv-full, eval = T}
errors1 <- double(nrow(covid))
errors2 <- double(nrow(covid))
for (i in 1:nrow(covid)) {
  train <- covid[-i, ]
  test <- covid[i, ]
  full_train <- lm(cases ~ .-time-ts, data = train[,-1])
  full_train1 <- lm(cases ~ ts*(.-time-ts), data = train[,-1])
  errors1[i] <- (predict(full_train,test) - test$cases)^2
  errors2[i] <- (predict(full_train1,test) - test$cases)^2
}

cv_fullmod <- mean(errors1)
print("CV score of full model, no time split")
cv_fullmod

cv_fullmod1 <- mean(errors2)
print("CV score of full model with time split")
cv_fullmod1
```
Next, we will attempt regularization approaches, owing to the correlation between predictors found in the Exploratory data analysis section. The two models are fitted again using LASSO. The first of them does not split recognize the time split, while the second does. These models have larger CV scores than the unregularized models, indicating that it is likely that all social behavior indicators are important in predicting case counts and informing that a ridge regression procedure might be helpful. However, the latter point does not seem to be the case. The outputs of the `R` code that fits these models are shown below.

```{r lasso, eval = T}
lasso_mod <- cv.glmnet(x = matrix(unlist(covid[,2:9]), nrow = nrow(covid)),
                       y = covid$cases)

print("CV score of LASSO model, no time split")
lasso_mod$cvm[lasso_mod$lambda == lasso_mod$lambda.min]
```

```{r lasso-by-time, eval = T}
lasso_mod1 <- cv.glmnet(x = matrix(unlist(covid[,c(2:9,12)]), nrow = nrow(covid)),
                       y = covid$cases)

print("CV score of LASSO model with time split")
lasso_mod1$cvm[lasso_mod1$lambda == lasso_mod1$lambda.min]

```

```{r ridge, eval = T}
ridge_mod <- cv.glmnet(x = matrix(unlist(covid[,2:9]), nrow = nrow(covid)),
                       y = covid$cases, alpha = 0)

print("CV score of ridge model, no time split")
ridge_mod$cvm[ridge_mod$lambda == ridge_mod$lambda.min]

```

```{r ridge-by-time, eval = T}
ridge_mod1 <- cv.glmnet(x = matrix(unlist(covid[,c(2:9,12)]), nrow = nrow(covid)),
                       y = covid$cases, alpha = 0)

print("CV score of ridge model with time split")
ridge_mod1$cvm[ridge_mod1$lambda == ridge_mod1$lambda.min]

```
Since both regularization approaches performed worse than the full model, it is concluded that they involved too much bias in the present setting. We still would like to see if the model can be simplified, so we now attempt stepwise variable selection on the full model that recognizes the time split. The function used, `stepAIC`, uses a likelihood-based criterion to add and remove predictors in steps. It is hoped that the properties of the likelihood make this stepwise selection procedure introduce less bias to the model, but we are not sure. The results of the procedure are shown below.

```{r stepwise-with-time, eval = T}
null <- lm(cases ~ 1, data = covid)
forsel_mod <- stepAIC(null , list(lower = null, upper = full_mod1), direction = "both", trace = 0)

knitr::kable(data.frame(Coefficients = summary(forsel_mod)$coefficients[,1], p = summary(forsel_mod)$coefficients[,4]), format = "pipe", caption = "Summary of stepwise selected model with time split")
```
The stepwise selection procedure ended up selecting a model which omits `resto_visit` and `public_transit` as well as interaction terms of the time split with `bar_visit` and `large_events`. Notably, the time split is kept. To correctly assess the quality of this model, we must perform model fitting and stepwise selection from the beginning on each training set, which is accounted for in the calculations. The CV score of the stepwise-selected procedure is as below.

```{r stepwise-by-time, eval = T}
errors <- double(nrow(covid))
for (i in 1:nrow(covid)) {
  train <- covid[-i, ]
  test <- covid[i, ]
  null_train <- lm(cases ~ 1, data = train)
  full_train <- lm(cases ~ ts*(.-date-time-ts), data = train)
  mod.train <- stepAIC(null_train, list(lower = null_train, upper = full_train), direction = "both", trace = 0)
  errors[i] <- (predict(mod.train,test) - test$cases)^2
}
print("CV score of stepwise-selected model with time split")
mean(errors)
```
We can see that the stepwise selection procedure gives a model with a CV score that is slightly better than the full model that recognizes the time split, so the preferred model is stepwise selected one from a predictive standpoint.

# Discussion

The stepwise selected model concludes that `other_mask_prop`, `mask_prop`, `large_events`, `distancing`, `worked_outside` and `bar_visit` are important predictors of COVID-19 case counts, where the relationships of `mask_prop`, `other_mask_prop`, `distancing` and `worked_outside` with `cases` change after July 25th, 2021. This is a superset of the variables concluded to be important from the inferential standpoint in the Analysis and results section. Since the first objective prioritizes the prediction of COVID-19 case counts, we will adopt the conclusion of the stepwise selected model instead of the full one; moreover, the inferential conclusion suffers from multiple comparison issues. To answer the second objective, we give the following estimate of the regression function of `cases`. Let \(Y\) be a random variable that represents case counts on a particular day, and let \(x_1,x_2,x_3,x_4,x_5,x_6\) be `other_mask_prop`, `mask_prop`, `large_events`, `distancing`, `worked_outside` and `bar_visit` on the same day. Then
\[\mathbb E[Y | \boldsymbol x = (x_1,x_2,x_3,x_4,x_5,x_6)] = 114.7556 - 4.9958x_1 + 2.5152x_2 - 4.1310x_3 + 0.6665x_4 + 1.4022x_5 + 0.2075x_6 = g_1(\boldsymbol x)\]
if the day is on or before July 25th, 2021 and
\[\mathbb E[Y | \boldsymbol x] = g_1(\boldsymbol x) - 557.2660 + 3.2087x_1 + 11.4271x_2 -15.0124x_4 + 4.7663x_5\]
if the day is after July 25th, 2021.

The current approach assumes that case counts and the included measures of social behavior are only linearly related, which is quite strong. Hence it can be argued that the analysis would be more complete if non-linear functions of the measures were included in the posited models, but it is decided that this is unnecessary. Firstly, the residual plot does not suggest that there are major uncaptured variations in the data unexplained by the model; there is only some heterocedasticity as well as an unusual line towards the left of the plot (i.e. for lower predicted case counts). The heterocedasticity is likely to be resolved by using log case counts instead of plain case counts, but they are monotonic functions of each other, so the answer to the first objective of the study is not likely to change. A method to eliminate the line in the residual plot is currently not known. Secondly, the QQ plot of the residuals shows that the normal errors assumption is not strongly violated. Altogether, the model assumptions hold up well, so the analysis may conclude here.

```{r res-plot-selected, fig.cap = "Diagnostic plots of stepwise-selected model.", fig.height=3}
par(mfrow = c(1,2))
plot(forsel_mod, 1)
plot(forsel_mod, 2)
```

It is reasonable to doubt the validity of the introduction of the time split in order to improve the predictive performance of the model. In essence, such a decision forces the model to say that COVID-19 case counts are associated differently to the aspects of social behavior studied after a certain point in time, so the time split is unnatural in a sense. There is only dubious evidence of this in the present data set in the univariate scatterplots and the results of the naive the regression tree, the latter of which was initially based on the assumption that COVID-19 case counts fluctuate in waves and that the tree would identify if there was indeed a transition of waves observed in the dataset. A more compelling approach for judging the validity of the time split as well as potentially identifying a better split in the dataset would be to cluster the observations in the dataset based on the measures of social behavior, effectively leading to a semi-supervised analysis approach. This was not pursued due to time constraints.

# References

