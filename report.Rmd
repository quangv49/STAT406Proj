---
title: "How does public behavior affect the spread of COVID-19?"
author: "Quang Vuong"
output:
  bookdown::pdf_document2
bibliography: bibliography.bib
csl: ieee.csl
toc: false
---

```{r setup, include=FALSE, message = F}
knitr::opts_chunk$set(echo = F, warning = F)
library(glmnet)
library(tidyverse)
library(MASS)
set.seed(20211127)
covid <- read.table("pblc_bhv_covid.csv",sep = ',', header=TRUE)
```

# Introduction

We wish to investigate how public behavior affects the spread of COVID-19 within a community. In particular, our goal is to identify which aspects of public behavior, such as visiting restaurants, visiting bars and using public transit, predict case counts. Since many other factors including population demographics, population density and policy decisions also affect the spread of COVID-19, it is best to focus on datasets for a sufficiently small geographical area (like a city or a county) so that the confounding factors unrelated to the study are controlled.

The present dataset, collected from the `{covidcast}` API, contains daily COVID-19 case counts for 88 days from June 5th, 2021 to September 5th, 2021, along with several indicators of public behavior, in Manhanttan, New York. The indicators of public behavior are:

- `distancing` = Percentage of survey respondents reporting that people maintained a distance of at least 6ft (%)
- `public_transit` = Percentage of survey respondents reporting that they used public transit in the last day (%)
- `worked_outside` = Percentage of survey respondents who was indoors (excluding home) in the last day (%)
- `large_events` = Percentage of survey respondents who attended a crowded event in the last day (%)
- `mask_prop` = Percentage of survey respondents who mostly wore a mask outside in the last week (%)
- `other_mask_prop` = Percentage of survey respondents saying that other people mostly wore a mask outside (%)
- `bar_visit` = Number of bar visits per 100000 people (visits per 100000 people)
- `resto_visit` = Number of restaurant visits per 100000 people (visits per 100000 people)

Most of these indicators are obtained from Facebook surveys. Taking into account the issues of survey data such as response bias and subjectivity of answers, it is extremely unlikely that the variables in the dataset track their true respective quantities. Instead, we opt to interpret these indicators as proxies of public behavior, which are potentially useful for prediction.

Now we will summarize our two objectives for this study:
\begin{enumerate}
\item Identify which of the above indicators are important in predicting COVID-19 case counts.
\item Identify a model which can be used to predict future COVID-19 case counts.
\end{enumerate}

Tupper et al. analyzed a model of COVID-19 transmission based on the specifics of social behavior such as reducing transmission rates through masks, social distancing and "bubbling", i.e. limiting social contact @tupper. They have concluded that distancing is the most powerful method to reduce transmission, while the effects of masking and bubbling are more situational but still significant. Therefore, based on this study, we would directly expect that `distancing`, `mask_prop` and `other_mask_prop` are important variables that predict lower COVID-19 case counts when at higher levels. It is feasible that the other predictors are important in predicting higher COVID-19 case counts when at higher levels as well, since an argument can be made that they do not pertain to bubbling. We then hypothesize that all predictors will appear in the final selected model.

# Exploratory data analysis

We will first briefly look at basic descriptive statistics of all variables involved.

```{r desc-stat, eval = T}
means <- sapply(subset(covid,select=-date), mean)
sds <- sapply(subset(covid,select=-date), sd)
desc <- data.frame(Mean = means, Standard.deviation = sds)

knitr::kable(desc, digits = 2, caption = "Descriptive statistics of predictors and case counts.", format = "pipe")

```

It is clear that all variables have very different scales from each other, so models with unstandardized and standardized variables will both be considered.

```{r indiv-boxplots, echo=FALSE, fig.height=8, fig.cap = "Boxplots of individual predictors and case counts.", eval = F}
par(mfrow=c(3,3))
for (i in 2:10) {
  boxplot(covid[i], xlab=names(covid)[i], ylab="Values")
}
```
It is the most instructive to now look at how predictors are related to case counts and each other. We plot all predictors against the number of cases in Figure \@ref(fig:plots-against-cases). `distancing`, `bar_visit` and `large_events` appear to have two clusters with different mean case counts. On the other hand, `mask_prop`, `other_mask_prop`, `resto_visit`, `public_transit` and `worked_outside` appear to have two trend lines. This strongly suggests that there are two clusters within the data that exhibit different relationships between case counts and public behavior.

```{r plots-against-cases, echo=FALSE, fig.height = 8, fig.cap = "Scatterplots of predictors against case counts."}

par(mfrow=c(3,3))

with(covid,plot(distancing,cases))
with(covid,plot(bar_visit,cases))
with(covid,plot(large_events,cases))
with(covid,plot(mask_prop,cases))
with(covid,plot(other_mask_prop,cases))
with(covid,plot(public_transit,cases))
with(covid,plot(resto_visit,cases))
with(covid,plot(worked_outside,cases))
```

To continue the examination of the dataset, we will now look at the covariance matrix of the predictors.

```{r correlations, fig.cap = "Entries of correlation matrix with high coefficients.", eval = T}
predictors <- subset(covid, select=-c(cases,date))

cor_pred <- cor(as.matrix(predictors))

for (i in 1:ncol(predictors)) {
  print(cor_pred[i, abs(cor_pred[i,]) > 0.6])
}
```

There is some substantial correlation between some predictors. In particular, `bar_visit`, `mask_prop`, `large_events` and `other_mask_prop` seem correlated with each other.

The most striking observation made so far is that there might be two clusters within the data that shows different relations between case counts and public behavior indicators, so we will now try to identify how the clusters are split. To do this, we attempt to fit a regression tree and look at the split at the root, which is plotted in Figure \@ref(fig:eda-tree). Initial inspection of this tree shows that there is clustering by date. After inspecting the plots of the predictors against `cases` within each cluster identified by the tree, it appears that splitting by date reduces the clustering behavior so that trends are now much clearer.

```{r eda-tree, echo = F, fig.height=3, fig.cap = "Regression tree to determine clusters in data.", eval = T}
library(rpart)

covid$time <- 1:nrow(covid)

eda_tree <- rpart(cases ~ .-date, data = covid, method = "anova")
plot(eda_tree, uniform = F, margin = 0.5)
text(eda_tree, pretty = T)
```



```{r plot-time-split, echo = F, fig.height=8, fig.cap = "Scatterplots of predictors against case counts on and before July 25th, 2021.", eval = F}
par(mfrow=c(3,3))

covid_ts1 <- covid[covid$time < 51.5, ]

with(covid_ts1,plot(distancing,cases))
with(covid_ts1,plot(bar_visit,cases))
with(covid_ts1,plot(large_events,cases))
with(covid_ts1,plot(mask_prop,cases))
with(covid_ts1,plot(other_mask_prop,cases))
with(covid_ts1,plot(public_transit,cases))
with(covid_ts1,plot(resto_visit,cases))
with(covid_ts1,plot(worked_outside,cases))

#Determines point in time where data is split.
#covid$date[covid$time == 51]
```

```{r plot-time-split2, echo = F, fig.height=8, fig.cap = "Scatterplots of predictors against case counts after July 25th, 2021.", eval = F}
par(mfrow=c(3,3))

covid_ts2 <- covid[covid$time >= 51.5, ]

with(covid_ts2,plot(distancing,cases))
with(covid_ts2,plot(bar_visit,cases))
with(covid_ts2,plot(large_events,cases))
with(covid_ts2,plot(mask_prop,cases))
with(covid_ts2,plot(other_mask_prop,cases))
with(covid_ts2,plot(public_transit,cases))
with(covid_ts2,plot(resto_visit,cases))
with(covid_ts2,plot(worked_outside,cases))
```

```{r corr_split, fig.cap = "Entries of correlation matrix with high coefficients for points on and before July 25th 2021.", eval = F}
predictors_ts <- subset(covid_ts1, select=-c(cases,date))

cor_pred_ts <- cor(as.matrix(predictors_ts))

for (i in 1:ncol(predictors_ts)) {
  print(cor_pred_ts[i, abs(cor_pred_ts[i,]) > 0.6])
}
```

```{r corr_whole_after_ts, fig.cap = "Entries of correlation matrix with high coefficients with `time` included.", eval = F}
predictors <- subset(covid, select=-c(cases,date))

cor_pred <- cor(as.matrix(predictors))

for (i in 1:ncol(predictors)) {
  print(cor_pred[i, abs(cor_pred[i,]) > 0.6])
}
```

Now, we will outline potential approaches to the analysis of this dataset. As mentioned above, we will analyze the both the original dataset and the dataset with time as an encoded categorical variable instead. Firstly, a full linear model will be fitted and interpreted from the inferential point of view to answer the first objective. Secondly, this model will be compared against ones obtained via a regularization approach and a variable selection approach. As interpretation is one of the goals of the analysis, we opt to avoid non-parametric approaches.

# Analysis and results

Let \(Y\) be a random variable that represents `cases` on a particular day, and let \(x_1,...,x_8\) denote the same for `distancing`, `bar_visit`,`large_events`,`mask_prop`,`other_mask_prop`,`public_transit`, `resto_visit`, and `worked_outside`. We first posit the model
\[Y = \beta_0 + \sum_{i=1}^8 \beta_ix_i + \varepsilon\]
where \(\varepsilon\) is normally distributed with mean \(0\) and standard deviation \(\sigma^2\). We examine this model first because it is the simplest. Least squares estimation is done on the data to estimate the coefficients in the model; we refrain from showing the results of the estimation before a preferred model has been selected.

```{r full, eval = T}
covid <- covid %>% mutate(ts = time >= 51.5)
full_mod <- lm(cases ~ .-date-time-ts, data = covid)
# knitr::kable(data.frame(Coefficients = summary(full_mod)$coefficients[,1],
#                         SE = summary(full_mod)$coefficients[,2],
#                         p = summary(full_mod)$coefficients[,4]),
#              format = "pipe", caption = "Summary of full model, no time split")
```
Now, the existence of the time split identified in the Exploratory data analysis section informs us to consider the model, with the same notation,

\[Y = \beta_0 + \beta_1 t + \sum_{i=1}^8 \beta_{i+1}x_i + \sum_{i=1}^8 \beta_{i+9} tx_i + \varepsilon\]

where \(\varepsilon\) is as before and \(t = 0\) if the observation is on or before July 25th, 2021 and \(1\) otherwise. Hence, the time split is encoded as a categorical variable to identify observations as before or after the time split. Again, least squares estimation is used to estimate the coefficients of this model.

```{r full-by-time, eval = T}
full_mod1 <- lm(cases ~ ts*(.-date-time), data = covid)
# knitr::kable(data.frame(Coefficients = summary(full_mod1)$coefficients[,1], SE = summary(full_mod1)$coefficients[,2], p = summary(full_mod1)$coefficients[,4]), format = "pipe", caption = "Summary of full model with time split")
```


```{r res-plots, fig.cap = "Diagnostic plots for full model without time split (top) and with time split (bottom)", fig.height = 4, eval = F}
par(mfrow=c(2,2))
plot(full_mod, 1)
plot(full_mod, 2)
plot(full_mod1, 1)
plot(full_mod1, 2)
```

We will now compare the models by their estimated mean squared prediction error. We will estimate this quantity with a leave-one-out cross-validation procedure that computes mean squared errors because it is flexible enough to adapt to the other model-fitting approaches that will be used in this study. The CV scores of the previous two full models are as follows. It is clear that the model that recognizes the time split performs much better.

```{r cv-full, eval = T}
errors1 <- double(nrow(covid))
errors2 <- double(nrow(covid))
for (i in 1:nrow(covid)) {
  train <- covid[-i, ]
  test <- covid[i, ]
  full_train <- lm(cases ~ .-time-ts, data = train[,-1])
  full_train1 <- lm(cases ~ ts*(.-time-ts), data = train[,-1])
  errors1[i] <- (predict(full_train,test) - test$cases)^2
  errors2[i] <- (predict(full_train1,test) - test$cases)^2
}

knitr::kable(data.frame(Model = c("Full linear, no time split", "Full linear with time split"),
                        Score = c(mean(errors1), mean(errors2)),
                        SE = c(sd(errors1)/sqrt(nrow(covid)), sd(errors2)/sqrt(nrow(covid)))),
             format = "pipe",
             caption = "CV scores and standard errors of the full linear models with and without the time split.")
```
Next, we will attempt regularization approaches, owing to the correlation between predictors found in the Exploratory data analysis section. The two models are fitted again using LASSO. The first of them does not split recognize the time split, while the second does. These models have larger CV scores than the unregularized models, indicating that it is likely that all social behavior indicators are important in predicting case counts and informing that a ridge regression procedure might be helpful. However, the latter point does not seem to be the case. The outputs of the `R` code that fits these models are shown below.

```{r lasso, eval = T}
lasso_mod <- cv.glmnet(x = matrix(unlist(covid[,2:9]), nrow = nrow(covid)),
                       y = covid$cases, nfolds = nrow(covid))
```

```{r lasso-by-time, eval = T}
lasso_mod1 <- cv.glmnet(x = matrix(unlist(covid[,c(2:9,12)]), nrow = nrow(covid)),
                       y = covid$cases, nfolds = nrow(covid))

```

```{r ridge, eval = T}
ridge_mod <- cv.glmnet(x = matrix(unlist(covid[,2:9]), nrow = nrow(covid)),
                       y = covid$cases, alpha = 0, nfolds = nrow(covid))

```

```{r ridge-by-time, eval = T}
ridge_mod1 <- cv.glmnet(x = matrix(unlist(covid[,c(2:9,12)]), nrow = nrow(covid)),
                       y = covid$cases, alpha = 0, nfolds = nrow(covid))


knitr::kable(
  data.frame(Model = c("LASSO, no time split", "LASSO with time split",
                       "Ridge, no time split", "Ridge with time split"),
             Score = c(lasso_mod$cvm[lasso_mod$lambda == lasso_mod$lambda.min],
                       lasso_mod1$cvm[lasso_mod1$lambda == lasso_mod1$lambda.min],
                       ridge_mod$cvm[ridge_mod$lambda == ridge_mod$lambda.min],
                       ridge_mod1$cvm[ridge_mod1$lambda == ridge_mod1$lambda.min]),
             SE = c(lasso_mod$cvsd[lasso_mod$lambda == lasso_mod$lambda.min],
                    lasso_mod1$cvsd[lasso_mod1$lambda == lasso_mod1$lambda.min],
                    ridge_mod$cvsd[ridge_mod$lambda == ridge_mod$lambda.min],
                    ridge_mod1$cvsd[ridge_mod1$lambda == ridge_mod1$lambda.min])),
  format = "pipe",
  caption = "CV scores and standard errors of regularized models."
)
```
Since both regularization approaches performed worse than the full model, it is concluded that they involved too much bias in the present setting. We still would like to see if the model can be simplified, so we now attempt stepwise variable selection on the full model that recognizes the time split. The function used, `stepAIC`, uses a likelihood-based criterion to add and remove predictors in steps. It is hoped that the properties of the likelihood make this stepwise selection procedure introduce less bias to the model, but we are not sure. To correctly assess the quality of this model, we must perform model fitting and stepwise selection from the beginning on each training set, which is accounted for in the calculations. The CV score of the stepwise-selected procedure is as below.

```{r stepwise-with-time, eval = T}
null <- lm(cases ~ 1, data = covid)
forsel_mod <- stepAIC(null , list(lower = null, upper = full_mod1), direction = "both", trace = 0)
```

```{r stepwise-by-time, eval = T}
errors <- double(nrow(covid))
for (i in 1:nrow(covid)) {
  train <- covid[-i, ]
  test <- covid[i, ]
  null_train <- lm(cases ~ 1, data = train)
  full_train <- lm(cases ~ ts*(.-date-time-ts), data = train)
  mod.train <- stepAIC(null_train, list(lower = null_train, upper = full_train), direction = "both", trace = 0)
  errors[i] <- (predict(mod.train,test) - test$cases)^2
}
print("CV score and standard deviation of stepwise-selected model with time split")
mean(errors)
sd(errors)/sqrt(nrow(covid))
```
We can see that the stepwise selection procedure gives a model with a CV score that is slightly better than the full model that recognizes the time split, so the preferred model is stepwise selected one from a predictive standpoint.

To judge if non-linear transformations of data are necssary, we will consult the residual and QQ plots of the stepwise-selected model in Figure \@ref(fig:res-plot-selected). Firstly, the residual plot does not suggest that there are major uncaptured variations in the data unexplained by the model; there is only some heterocedasticity as well as an unusual line towards the left of the plot (i.e. for lower predicted case counts). The heterocedasticity is likely to be resolved by using log case counts instead of plain case counts, but they are monotonic functions of each other, so the answer to the first objective of the study is not likely to change. A method to eliminate the line in the residual plot is currently not known. Secondly, the QQ plot of the residuals shows that the normal errors assumption is not strongly violated. Altogether, the model assumptions hold up well, so the analysis may conclude here, with the stepwise-selected model being the most preferred one. There is no need to reconsider models with standardized variables because the all of the linear models fitted are scale-invariant, and `cv.glmnet` has built-in scaling.

```{r res-plot-selected, fig.cap = "Diagnostic plots of stepwise-selected model.", fig.height=3}
par(mfrow = c(1,2))
plot(forsel_mod, 1)
plot(forsel_mod, 2)
```

The stepwise selection procedure ended up selecting a model which omits `resto_visit` and `public_transit` as well as interaction terms of the time split with `bar_visit` and `large_events`. Notably, the time split is kept.  The coefficient estimates, their standard errors and \(p\)-values are shown in the following table.

```{r step-sel-table, eval = T}
knitr::kable(data.frame(Coefficients = summary(forsel_mod)$coefficients[,1], SE = summary(forsel_mod)$coefficients[,2], p = summary(forsel_mod)$coefficients[,4]), format = "pipe", caption = "Summary of stepwise selected model with time split")
```


# Discussion

The predictive standpoint focuses on which predictors appear in the selected model without regards for hypothesis testing concerns, so the stepwise-selected model concludes that `other_mask_prop`, `mask_prop`, `large_events`, `distancing`, `worked_outside` and `bar_visit` are important predictors of COVID-19 case counts, where the relationships of `mask_prop`, `other_mask_prop`, `distancing` and `worked_outside` with `cases` change after July 25th, 2021. Since the first objective prioritizes the prediction of COVID-19 case counts, this is a satisfactory conclusion. To answer the second objective, we give the following estimate of the regression function of `cases`. Let \(Y\) be a random variable that represents case counts on a particular day, and let \(x_1,x_2,x_3,x_4,x_5,x_6\) be `other_mask_prop`, `mask_prop`, `large_events`, `distancing`, `worked_outside` and `bar_visit` on the same day. Then
\[\mathbb E[Y | \boldsymbol x = (x_1,x_2,x_3,x_4,x_5,x_6)] = 114.7556 - 4.9958x_1 + 2.5152x_2 - 4.1310x_3 + 0.6665x_4 + 1.4022x_5 + 0.2075x_6 = g_1(\boldsymbol x)\]
if the day is on or before July 25th, 2021 and
\[\mathbb E[Y | \boldsymbol x] = g_1(\boldsymbol x) - 557.2660 + 3.2087x_1 + 11.4271x_2 -15.0124x_4 + 4.7663x_5\]
if the day is after July 25th, 2021. Care must be taken in interpreting that coefficients in this model, since they only reflect how expected case counts vary when exactly one indicator of social behavior changes and other indicators are held constant. This does not lend to a natural interpretation of what the model says about how each indicator predicts case counts as a whole; to pursue this objective, the current methods are not suitable.

It is reasonable to doubt the validity of the introduction of the time split in order to improve the predictive performance of the model, which essentially states that the relationship between case counts and public behavior change after a certain point in time. There is only dubious evidence of this in the present data set in the univariate scatterplots and the results of the naive the regression tree, the latter of which was initially based on the assumption that COVID-19 case counts fluctuate in waves and that the tree would identify if there was indeed a transition of waves observed in the dataset. A more compelling approach would essentially be a semi-supervised learning procedure, which was not pursued due to time constraints.

# References

